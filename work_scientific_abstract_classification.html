<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta content="IE=edge" http-equiv="X-UA-Compatible">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <meta content="description" name="description">
  <meta name="google" content="notranslate" />


  <!-- Disable tap highlight on IE -->
  <meta name="msapplication-tap-highlight" content="no">
  <link href="./assets/favicon.ico" rel="icon">
  <link href="./main.3f6952e4.css" rel="stylesheet">
  <title>Scientific Abstract Classification</title>  

  
<style>
  body {
    background-color: black;
    color: white;
  }

  .custom-header {
    background-color: black;
    color: white;
  }
  table {
    border-collapse: collapse;
    width: 100%;
    border: 1px solid #ddd;
  }

  th, td {
    border: 1px solid #ddd;
    padding: 8px;
    text-align: center;
  }

  th {
    background-color: #3a0ca3;
  }

  


</style>
</head>

<body class="">
<div id="site-border-left"></div>
<div id="site-border-right"></div>
<div id="site-border-top"></div>
<div id="site-border-bottom"></div>

<header>
  <nav class="navbar  navbar-fixed-top navbar-defaul custom-header">
    <div class="container">
        <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse" aria-expanded="false">
          <span class="sr-only">Toggle navigation</span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>

      <div class="collapse navbar-collapse" id="navbar-collapse">
        <ul class="nav navbar-nav">
          <li><a href="./index.html" title="" style="color: #fff;">
              <span class="fa-icon">
                <i class="fa fa-hand-peace-o" aria-hidden="true" style="font-size:16px;color:#fff;"></i>
              </span>
              Back to My Hello Page</a></li>
          <li><a href="./works.html" title="" style="color: #fff;">
              <span class="fa-icon">
                <i class="fa fa-bar-chart" aria-hidden="true" style="font-size:16px;color:#fff;"></i>
              </span>
              Back to My Works</a></li>
        </ul>

        <ul class="nav navbar-nav navbar-right navbar-small visible-md visible-lg">
          <li><a href="./work_nyc_311_analysis.html" style="color: #fff;">001</a></li>
          <li><a href="./work_customer_testimonial.html" style="color: #fff;">002</a></li>
          <li><a href="./work_scientific_abstract_classification.html" class="active" style="color: #fff;">003</a></li>
          <li><a href="./work_dog_breed.html" style="color: #fff;">004</a></li>
          <li><a href="./work_landmark.html" style="color: #fff;">005</a></li>
        </ul>

      </div> 
    </div>
  </nav>
</header>

<div class="section-container custom-header">
  <div class="container">
    <div class="row">
      <div class="col-xs-12">
        <img src="./assets/images/scientifc_classification/background.jpg" class="img-responsive" alt="">
        <div class="card-container custom-header" style="background-color: transparent;">
          <div class="text-center">
            <h1 class="h2 custom-header" style="background-color: rgba(0, 0, 0, 0.5);">003 : Scientific Abstract Classification</h1>
          </div>
          <p class="text-center">
            In scientific research, classifying and organizing articles is crucial due to the increasing number of publications. Using Transformer models and ensemble learning is an effective method for automated categorization. Transformers excel in processing language and complex data, while ensemble learning combines independent models to enhance overall accuracy and generalization.<br>
            This approach aids researchers, students, and experts in accessing relevant materials easily.
          </p>
        </div>
      </div>     
      <div class="col-xs-12">
        <div class="row">
          <div class="col-xs-12">
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <h3 class="h3 custom-header text-center">
              <font color="#4CC9F0">Project Color Palette</font>
            </h3>
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <img src="./assets/images/scientifc_classification/palette.png" class="img-responsive">
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <h3 class="h3 custom-header text-center">
              <font color="#4CC9F0">Model Framework</font>
            </h3>
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <img src="./assets/images/scientifc_classification/framework.png" class="img-responsive" alt="">
            <p align="justify">
              The system architecture comprises three main classification models:
              <ul>
                <li>Model 1: Standalone RoBERTA </li>
                <li>Model 2: RoBERTA + LDA </li>
                <li>Model 3: TF-IDF + Logistic Regression </li>
              </ul>
              All three models independently contribute to predicting the outcome of the input text segment. The final result will
              be determined through a majority voting system, selecting the outcome with the highest number of votes (most
              frequent). <br>
              In the above diagram, 
              <ul>
                <li>  Em = Embedding </li>
                <li>  Tm = Topic Models </li>
                <li>  FC = Fully Connected Layer </li>
                <li>  C1 to C2 correspond to the groups CR, CL, ... </li>
              </ul>
            </p>

            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <h3 class="h3 custom-header text-center">
              <font color="#4CC9F0">Input and Output</font>
            </h3>
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <p align="justify">
              The challenge is how to automatically categorize scientific articles into specific topics, fields, or research types.
              Given the diversity and complexity of articles, accurate automated classification is a significant challenge. <br>
              The <strong>input</strong> consists of abstracts of scientific articles represented as text. <br>
              The <strong>output</strong> is the classification of each article into topics, fields, or research types. For example, labels could be
              topics like biology, machine learning, physics, or fields like medicine, information technology, economics.
              The goal is to predict and assign an appropriate label to each article based on its content and context. <br>
              In the context of this project, the articles will be classified into the following 7 groups:
              <ul>
                <li>Computation and Language (CL)</li>
                <li>Cryptography and Security (CR)</li>
                <li>Distributed and Cluster Computing (DC)</li>
                <li>Data Structures and Algorithms (DS)</li>
                <li>Logic in Computer Science (LO)</li>
                <li>Networking and Internet Architecture (NI)</li>
                <li>Software Engineering (SE)</li>
              </ul>
            </p>
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <h3 class="h3 custom-header text-center">
              <font color="#4CC9F0">Dataset for Experiment</font>
            </h3>
            <hr
              style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <p>The dataset provided for the sharing task of "The First Workshop and Shared Task on Topic Classification in
              Scientific Articles" (SPDRA 2021) includes 16,800 training examples, 11,200 validation examples, and 7,000 test
              examples.</p>
            <table>
              <tr>
                <th>Category</th>
                <th>Train</th>
                <th>Validation</th>
                <th>Test</th>
              </tr>
              <tr>
                <td>Computation and Language (CL)</td>
                <td>2,740</td>
                <td>1,866</td>
                <td>1,194</td>
              </tr>
              <tr>
                <td>Cryptography and Security (CR)</td>
                <td>2,660</td>
                <td>1,835</td>
                <td>1,105</td>
              </tr>
              <tr>
                <td>Distributed and Cluster Computing (DC)</td>
                <td>1,042</td>
                <td>1,355</td>
                <td>803</td>
              </tr>
              <tr>
                <td>Data Structures and Algorithms (DS)</td>
                <td>2,737</td>
                <td>1,774</td>
                <td>1,089</td>
              </tr>
              <tr>
                <td>Logic ib Computer Science (LO)</td>
                <td>1,811</td>
                <td>1,217</td>
                <td>772</td>
              </tr>
              <tr>
                <td>Networking and Internet Architecture (NI)</td>
                <td>2,764</td>
                <td>1,826</td>
                <td>1,210</td>
              </tr>
              <tr>
                <td>Software Engineering (SE)</td>
                <td>2,046</td>
                <td>1,327</td>
                <td>827</td>
              </tr>
              <tr>
                <td>Total</td>
                <td>16,800</td>
                <td>11,200</td>
                <td>7,000</td>
              </tr>
            </table>
            <p>
              <cite>Reddy, Saichethan; Saini, Naveen (2021), “SDPRA 2021 Shared Task Data”</cite>,
              <a href="https://doi.org/10.17632/njb74czv49.1">Mendeley Data, V1, doi: 10.17632/njb74czv49.1</a>
            </p>
            <p>
              However, due to time and computational constraints, the report only utilizes a random sample of 100 documents.
              The distribution of topics and documents across training, validation, and test sets is as follows:
            </p>
            <table>
              <tr>
                <th style="background-color: #7209b7;">Category</th>
                <th style="background-color: #7209b7;">Train</th>
                <th style="background-color: #7209b7;">Validation</th>
                <th style="background-color: #7209b7;">Test</th>
              </tr>
              <tr>
                <td>Computation and Language (CL)</td>
                <td>100</td>
                <td>20</td>
                <td>20</td>
              </tr>
              <tr>
                <td>Cryptography and Security (CR)</td>
                <td>100</td>
                <td>20</td>
                <td>20</td>
              </tr>
              <tr>
                <td>Distributed and Cluster Computing (DC)</td>
                <td>100</td>
                <td>20</td>
                <td>20</td>
              </tr>
              <tr>
                <td>Data Structures and Algorithms (DS)</td>
                <td>100</td>
                <td>20</td>
                <td>20</td>
              </tr>
              <tr>
                <td>Logic ib Computer Science (LO)</td>
                <td>100</td>
                <td>20</td>
                <td>20</td>
              </tr>
              <tr>
                <td>Networking and Internet Architecture (NI)</td>
                <td>100</td>
                <td>20</td>
                <td>20</td>
              </tr>
              <tr>
                <td>Software Engineering (SE)</td>
                <td>100</td>
                <td>20</td>
                <td>20</td>
              </tr>
              <tr>
                <td>Total</td>
                <td>700</td>
                <td>140</td>
                <td>140</td>
              </tr>
            </table>
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <h3 class="h3 custom-header text-center">
              <font color="#4CC9F0">Experimental Result</font>
            </h3>
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <p align="justify">
              <strong><u>Confusion Matrix:</u></strong> <br>
              A confusion matrix is a matrix chart used to evaluate the performance of a classification model.
              It helps measure the differences between predictions made by the model and the actual labels. <br>
              <br>
              How to interpret the confusion matrix:
              <ul>
                <li>For each class, the number of actual samples correctly classified into that class is along the main diagonal from the
              top-left to the bottom-right.</li>
                <li>The number of misclassified samples into other classes is in cells outside the main diagonal.</li>
              </ul>
            </p>
            <img src="./assets/images/scientifc_classification/confusion_matrix.png" class="img-responsive">
            <p>
              The model predicts results for 140 text segments from the test set. <br>
              
              The results of the confusion matrix show that the standalone RoBERTa group has scattered prediction results and a lower
              number of correct predictions compared to the other models. <br>
              Combining predictions from multiple models and using voting effectively mitigated the weaknesses of standalone RoBERTa. However, the TF-IDF + Logistic Regression model provides the
              best results. <br>
              <strong>==></strong> Therefore, for this project, model enhancement could involve assigning weights to the model votes (Weighted Votings) to further improve
              ensemble model performance. <br>
              <br>
              <strong><u>Model Accuracy:</u></strong><br>
              Model has the accuracy score reachs 59%. <br>
              However, resource and time constraints have hindered achieving a better result.
              The above is a demonstration on a very small subset of the dataset. When performed on the entire dataset, it is possible to expect an accuracy of over 90%. <br>

              <img src="./assets/images/scientifc_classification/accuracy.png" class="img-responsive text-center">
            </p>
            
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <h3 class="h3 custom-header text-center">
              <font color="#4CC9F0">Deployment</font>
            </h3>
            <hr style="border: 0; height: 1px; background-image: linear-gradient(to right, rgba(255, 255, 255, 0), rgba(255, 255, 255, 0.75), rgba(255, 255, 255, 0));">
            <img src="./assets/images/scientifc_classification/demo.gif" class="img-responsive">           

          </div>
        </div>
      </div>
    </div>
  </div>
</div>


<script>
  document.addEventListener("DOMContentLoaded", function (event) {
     navActivePage();
  });
</script>
<script type="text/javascript" src="./main.70a66962.js"></script>

</body>

</html>